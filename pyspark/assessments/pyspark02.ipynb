{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3cd4ef-cf19-4396-98b1-caf505b754db",
   "metadata": {},
   "source": [
    "## Importing pyspark, findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1bd619-2674-4a4d-bcbe-ea55b2edf178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Pyspark_examples_02').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff36a1-5f1b-4686-b944-6123e9ffb0ee",
   "metadata": {},
   "source": [
    "## Creating a RDD using spark.createDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3b893c-4ac6-42c9-96f1-1b8e2750536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),(\"Michael\",\"Rose\",\"USA\",\"NY\"), \\\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),(\"Maria\",\"Jones\",\"USA\",\"FL\") \\\n",
    "  ]\n",
    "columns=[\"firstname\",\"lastname\",\"country\",\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54713637-0963-4765-b208-beba0a44690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(firstname='James', lastname='Smith', country='USA', state='CA'),\n",
       " Row(firstname='Michael', lastname='Rose', country='USA', state='NY'),\n",
       " Row(firstname='Robert', lastname='Williams', country='USA', state='CA'),\n",
       " Row(firstname='Maria', lastname='Jones', country='USA', state='FL')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.show()\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4807b8a7-40bc-4958-b09b-25482190a7d1",
   "metadata": {},
   "source": [
    "## Selecting specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fec6a8-9a9d-4a1e-b91f-f1b6d668f435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA', 'NY', 'CA', 'FL']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_data = df.rdd.map(lambda x: x[3]).collect()\n",
    "states_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d84e648-adde-4a4c-adf9-4bd8db049c37",
   "metadata": {},
   "source": [
    "## Removing Duplicates from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed08db0-32fd-4997-8e27-cfccb269fbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA', 'NY', 'FL']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "res = list(OrderedDict.fromkeys(states_data))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e3588-935a-4acc-978e-198584f2aa18",
   "metadata": {},
   "source": [
    "## Selecting specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ada4c34-9296-4e86-9392-6cbd51b81728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA', 'NY', 'CA', 'FL']\n"
     ]
    }
   ],
   "source": [
    "states2=df.rdd.map(lambda x: x.state).collect()\n",
    "print(states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e38e10f-0ae9-4a93-8a10-a8b013d4afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(state='CA'), Row(state='NY'), Row(state='CA'), Row(state='FL')]\n"
     ]
    }
   ],
   "source": [
    "states3=df.select(df.state).collect()\n",
    "print(states3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d3d9cb-d7c3-4deb-93ba-cbb86cfabc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA', 'NY', 'CA', 'FL']\n"
     ]
    }
   ],
   "source": [
    "states4=df.select(df.state).rdd.flatMap(lambda x: x).collect()\n",
    "print(states4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8360a-c67b-4b27-95cf-9a9797dfe625",
   "metadata": {},
   "source": [
    "## Converting a RDD to pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69765790-7b31-4947-9c8b-33ed44e92330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA', 'NY', 'CA', 'FL']\n"
     ]
    }
   ],
   "source": [
    "states5=df.select(df.state).toPandas()['state']\n",
    "states6=list(states5)\n",
    "print(states6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "446c93fd-f423-4d31-b5ff-85cbacd58926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA', 'NY', 'CA', 'FL']\n",
      "['James', 'Michael', 'Robert', 'Maria']\n"
     ]
    }
   ],
   "source": [
    "pandDF=df.select(df.state,df.firstname).toPandas()\n",
    "print(list(pandDF['state']))\n",
    "print(list(pandDF['firstname']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12182f9c-4e09-4fbc-bd83-7651bba2f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>firstname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY</td>\n",
       "      <td>Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>Robert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FL</td>\n",
       "      <td>Maria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state firstname\n",
       "0    CA     James\n",
       "1    NY   Michael\n",
       "2    CA    Robert\n",
       "3    FL     Maria"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d0db8-13d8-4f7a-aa9e-3d16876de9f1",
   "metadata": {},
   "source": [
    "## creating a RDD using pyspark.sql.types, pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66618d4-9392-4dfb-9018-7626ccd1b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import to_timestamp, current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fc4e602-f44a-4b4e-9044-36541c7b7734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|seq|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_schema = StructType([StructField(\"seq\", StringType(), True)])\n",
    "new_data = [('1',)]  # Corrected line, using a tuple instead of a list\n",
    "new_df = spark.createDataFrame(new_data, schema=temp_schema)\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f68a6-718c-4bdd-9a13-6d104baea76a",
   "metadata": {},
   "source": [
    "## Creating a python dataframe using pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d298b08e-d2f8-4016-9554-3a9f2e92ec50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scott</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ann</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  age\n",
       "0   Scott   50\n",
       "1    Jeff   45\n",
       "2  Thomas   54\n",
       "3     Ann   34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "new_data1 = [['Scott', 50], ['Jeff', 45], ['Thomas', 54],['Ann',34]] \n",
    "pandasDF = pd.DataFrame(data=new_data1, columns=['Name', 'age'])\n",
    "pandasDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b602c7-4d3d-4611-88b0-61cbf277735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|age|\n",
      "+------+---+\n",
      "| Scott| 50|\n",
      "|  Jeff| 45|\n",
      "|Thomas| 54|\n",
      "|   Ann| 34|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF1 = spark.createDataFrame(pandasDF)\n",
    "sparkDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e20f1d8e-2143-45d6-a3c1-7d18e2c1682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906be21d-c7d2-4e77-9821-a50763713928",
   "metadata": {},
   "source": [
    "### using collect to print all rows of the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f310bd3f-889c-4dfa-8572-2bc172a94bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Scott', age=50),\n",
       " Row(Name='Jeff', age=45),\n",
       " Row(Name='Thomas', age=54),\n",
       " Row(Name='Ann', age=34)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDF1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb4067-07e0-47ed-a374-6ffe0147bfe2",
   "metadata": {},
   "source": [
    "### using count to print the number all rows of the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c93e5a51-a5a4-461c-a88b-effd39d6119b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDF1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b822d3-ed7f-4728-9841-84ea1a8962cd",
   "metadata": {},
   "source": [
    "### using take to print the first n no of rows of the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "714c1264-c6f8-4a54-8251-10e82cda7cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Scott', age=50), Row(Name='Jeff', age=45)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDF1.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a79b7e-f0ac-49de-aa07-dd204ff0d9d6",
   "metadata": {},
   "source": [
    "### using first prints the first row of the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4525665b-274b-4b22-b64b-d9626d0b6c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Name='Scott', age=50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDF1.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1a5f9-c3b7-4dbb-8c43-27a9444dac91",
   "metadata": {},
   "source": [
    "### using parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cba7113-e128-4205-9714-6136d86174c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d528a0d-35ae-4011-8a7e-4eb58a8e5079",
   "metadata": {},
   "source": [
    "### using reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb33818b-4ce0-4c08-be8a-2f5f9909bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "reduced_rdd = sc.parallelize([1,2,3,4,5,6])\n",
    "print(reduced_rdd.reduce(lambda x,y:x+y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8463e1-8915-496d-a565-ef35b77042b3",
   "metadata": {},
   "source": [
    "### using saveAsTextFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137cf90-d74c-46a2-8d5a-63560e9b2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_rdd.saveAsTextFile('file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597fa39-b775-49ba-bff5-cb6c3359ed2c",
   "metadata": {},
   "source": [
    "### Selecting multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cfb737d-f7ac-4481-b4ec-d8bd943802ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "| Scott| 50|\n",
      "|  Jeff| 45|\n",
      "|Thomas| 54|\n",
      "|   Ann| 34|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_cols = sparkDF1.select(['Name','age'])\n",
    "multi_cols.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
